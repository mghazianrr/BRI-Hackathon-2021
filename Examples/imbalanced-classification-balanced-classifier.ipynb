{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":false},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":32,"outputs":[{"output_type":"stream","text":"/kaggle/input/bri-data-hackathon-pa/sample_submission.csv\n/kaggle/input/bri-data-hackathon-pa/data_description.csv\n/kaggle/input/bri-data-hackathon-pa/train.csv\n/kaggle/input/bri-data-hackathon-pa/test.csv\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Hello everyone!\n\nThis notebook presents an example of how to deal with imbalanced data. I will start with several oversampling methods, combination methods, and balanced classifiers.\n\nIf you have any questions regarding the code, please comment below. I will update the notebook accordingly.\n\n**Please do upvote the notebook if this notebook helps you, as it will be a benchmark for me to do more work in the future. Thank you :)**\n\n**Note: I do not do the feature engineering here, so the result may sub-optimal**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\nfrom imblearn.pipeline import Pipeline\nfrom sklearn.model_selection import cross_val_score\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":70,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read train and test set\ntrain = pd.read_csv(\"/kaggle/input/bri-data-hackathon-pa/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/bri-data-hackathon-pa/test.csv\")","execution_count":38,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop null values\ntrain = train.dropna()","execution_count":46,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split train set into dependent variables and independent variable\ny = train['Best Performance']\nX = train.drop('Best Performance', axis=1)","execution_count":47,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.value_counts()","execution_count":62,"outputs":[{"output_type":"execute_result","execution_count":62,"data":{"text/plain":"0    9515\n1    1637\nName: Best Performance, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert to dummy variables\nX = pd.get_dummies(X)\ntest = pd.get_dummies(test)","execution_count":48,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extract the common features between train and test set and use it to filter the train and test set\ncommon = list(set(X.columns).intersection(set(test.columns)))\nX = X[common]\ntest = test[common]","execution_count":49,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Oversampling"},{"metadata":{"trusted":true},"cell_type":"code","source":"# ADASYN, BorderlineSMOTE, KMeansSMOTE, RandomOverSampler, SMOTE, SVMSMOTE\nfrom imblearn.over_sampling import *","execution_count":51,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"over_methods = [\n    ADASYN(random_state=7),\n    BorderlineSMOTE(random_state=7),\n    RandomOverSampler(random_state=7),\n    SMOTE(random_state=7),\n    SVMSMOTE(random_state=7)\n]","execution_count":83,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifiers =[\n    RandomForestClassifier(n_estimators=1000),\n    ExtraTreesClassifier(n_estimators=1000)\n]","execution_count":84,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Benchmarks\nfor classifier in classifiers:\n        \n    steps = [('model', classifier)]\n\n    pipeline = Pipeline(steps=steps)\n\n    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=7)\n    scores = cross_val_score(pipeline, X, y, scoring='roc_auc', cv=cv, n_jobs=-1)\n    \n    print(\"ROC-AUC Score for\", classifier, \"without over-sampling is\", round(np.mean(scores),5))","execution_count":87,"outputs":[{"output_type":"stream","text":"ROC-AUC Score for RandomForestClassifier(n_estimators=1000) without over-sampling is 0.57059\nROC-AUC Score for ExtraTreesClassifier(n_estimators=1000) without over-sampling is 0.55623\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Iterates over classifiers and over_methods\nfor classifier in classifiers:\n    for method in over_methods:\n        \n        steps = [('over', method),\n                 ('model', classifier)]\n\n        pipeline = Pipeline(steps=steps)\n\n        cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=7)\n        scores = cross_val_score(pipeline, X, y, scoring='roc_auc', cv=cv, n_jobs=-1)\n    \n        print(\"ROC-AUC Score for\", classifier, \"and\", method, \"is\", round(np.mean(scores),5))","execution_count":86,"outputs":[{"output_type":"stream","text":"ROC-AUC Score for RandomForestClassifier(n_estimators=1000) and ADASYN(random_state=7) is 0.55706\nROC-AUC Score for RandomForestClassifier(n_estimators=1000) and BorderlineSMOTE(random_state=7) is 0.55706\nROC-AUC Score for RandomForestClassifier(n_estimators=1000) and RandomOverSampler(random_state=7) is 0.574\nROC-AUC Score for RandomForestClassifier(n_estimators=1000) and SMOTE(random_state=7) is 0.55566\nROC-AUC Score for RandomForestClassifier(n_estimators=1000) and SVMSMOTE(random_state=7) is 0.56108\nROC-AUC Score for ExtraTreesClassifier(n_estimators=1000) and ADASYN(random_state=7) is 0.53394\nROC-AUC Score for ExtraTreesClassifier(n_estimators=1000) and BorderlineSMOTE(random_state=7) is 0.535\nROC-AUC Score for ExtraTreesClassifier(n_estimators=1000) and RandomOverSampler(random_state=7) is 0.55442\nROC-AUC Score for ExtraTreesClassifier(n_estimators=1000) and SMOTE(random_state=7) is 0.53567\nROC-AUC Score for ExtraTreesClassifier(n_estimators=1000) and SVMSMOTE(random_state=7) is 0.53873\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Combination Sampling\n#### Combination of over- and under-sampling methods\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.combine import SMOTEENN, SMOTETomek","execution_count":88,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"combinations = [\n    SMOTEENN(random_state=7),\n    SMOTETomek(random_state=7)\n]","execution_count":89,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifiers =[\n    RandomForestClassifier(n_estimators=1000),\n    ExtraTreesClassifier(n_estimators=1000)\n]","execution_count":90,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Iterates over classifiers and combinations\nfor classifier in classifiers:\n    for combination in combinations:\n        \n        steps = [('comb', combination),\n                 ('model', classifier)]\n\n        pipeline = Pipeline(steps=steps)\n\n        cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=7)\n        scores = cross_val_score(pipeline, X, y, scoring='roc_auc', cv=cv, n_jobs=-1)\n    \n        print(\"ROC-AUC Score for\", classifier, \"and\", combination, \"is\", round(np.mean(scores),5))","execution_count":93,"outputs":[{"output_type":"stream","text":"ROC-AUC Score for RandomForestClassifier(n_estimators=1000) and SMOTEENN(random_state=7) is 0.55594\nROC-AUC Score for RandomForestClassifier(n_estimators=1000) and SMOTETomek(random_state=7) is 0.5553\nROC-AUC Score for ExtraTreesClassifier(n_estimators=1000) and SMOTEENN(random_state=7) is 0.53167\nROC-AUC Score for ExtraTreesClassifier(n_estimators=1000) and SMOTETomek(random_state=7) is 0.53454\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Ensemble of Samplers\n#### Classifier including inner balancing samplers\nFor more info: https://imbalanced-learn.org/stable/ensemble.html"},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.ensemble import BalancedBaggingClassifier, RUSBoostClassifier, BalancedRandomForestClassifier","execution_count":97,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Balanced Bagging Classifier\nbbc = BalancedBaggingClassifier(base_estimator=DecisionTreeClassifier(),\n                                n_estimators = 1000,\n                                sampling_strategy='auto',\n                                replacement=False,\n                                random_state=0)\ncv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=7)\nscores = cross_val_score(bbc, X, y, scoring='roc_auc', cv=cv, n_jobs=-1)\nprint(\"ROC-AUC Score for Balanced Bagging Classifier is\", round(np.mean(scores),5))","execution_count":98,"outputs":[{"output_type":"stream","text":"ROC-AUC Score for Balanced Bagging Classifier is 0.58633\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Balanced Random Forest Classifier\nbrf = BalancedRandomForestClassifier(n_estimators = 1000,\n                                     sampling_strategy='auto',\n                                     replacement=False,\n                                     random_state=0)\ncv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=7)\nscores = cross_val_score(brf, X, y, scoring='roc_auc', cv=cv, n_jobs=-1)\nprint(\"ROC-AUC Score for Balanced Random Forest Classifier is\", round(np.mean(scores),5))","execution_count":99,"outputs":[{"output_type":"stream","text":"ROC-AUC Score for Balanced Random Forest Classifier is 0.57839\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# RUSBoostClassifier\nrusbc = RUSBoostClassifier(n_estimators = 1000,\n                           random_state = 0)\ncv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=7)\nscores = cross_val_score(rusbc, X, y, scoring='roc_auc', cv=cv, n_jobs=-1)\nprint(\"ROC-AUC Score for RUSBoostClassifier is\", round(np.mean(scores),5))","execution_count":100,"outputs":[{"output_type":"stream","text":"ROC-AUC Score for RUSBoostClassifier is 0.54722\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Summary\n\nNow we obtain the highest score are:\n- Balanced Bagging Classifier is 0.58633\n- Balanced Random Forest Classifier is 0.57839\n- RandomForestClassifier(n_estimators=1000) and RandomOverSampler() is 0.574\n- RandomForestClassifier(n_estimators=1000) without over-sampling is 0.57059 [BENCHMARK]\n\n### What's next?\n\n- Try to do feature engineering first or try another encoder method and run all the code to calculate the scores.\n- Tune the classifier with GridSearchCV, RandomizedSearchCV, or Bayesian Optimization. See my other notebook here: https://www.kaggle.com/yevonnaelandrew/starter-xgboost-bayesian-optimization\n- Try other classification algorithms, like XGBoost, CatBoost, LGBM."}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat":4,"nbformat_minor":4}